{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist Salaries - Data Processing and analysis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3755, 11)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3755 entries, 0 to 3754\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   work_year           3755 non-null   int64 \n",
      " 1   experience_level    3755 non-null   object\n",
      " 2   employment_type     3755 non-null   object\n",
      " 3   job_title           3755 non-null   object\n",
      " 4   salary              3755 non-null   int64 \n",
      " 5   salary_currency     3755 non-null   object\n",
      " 6   salary_in_usd       3755 non-null   int64 \n",
      " 7   employee_residence  3755 non-null   object\n",
      " 8   remote_ratio        3755 non-null   int64 \n",
      " 9   company_location    3755 non-null   object\n",
      " 10  company_size        3755 non-null   object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 322.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ds_salaries.csv')\n",
    "print(df.shape)\n",
    "print('\\n')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>80000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>85847</td>\n",
       "      <td>ES</td>\n",
       "      <td>100</td>\n",
       "      <td>ES</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>30000</td>\n",
       "      <td>USD</td>\n",
       "      <td>30000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>25500</td>\n",
       "      <td>USD</td>\n",
       "      <td>25500</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>175000</td>\n",
       "      <td>USD</td>\n",
       "      <td>175000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120000</td>\n",
       "      <td>USD</td>\n",
       "      <td>120000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                 job_title   \n",
       "0       2023               SE              FT  Principal Data Scientist  \\\n",
       "1       2023               MI              CT               ML Engineer   \n",
       "2       2023               MI              CT               ML Engineer   \n",
       "3       2023               SE              FT            Data Scientist   \n",
       "4       2023               SE              FT            Data Scientist   \n",
       "\n",
       "   salary salary_currency  salary_in_usd employee_residence  remote_ratio   \n",
       "0   80000             EUR          85847                 ES           100  \\\n",
       "1   30000             USD          30000                 US           100   \n",
       "2   25500             USD          25500                 US           100   \n",
       "3  175000             USD         175000                 CA           100   \n",
       "4  120000             USD         120000                 CA           100   \n",
       "\n",
       "  company_location company_size  \n",
       "0               ES            L  \n",
       "1               US            S  \n",
       "2               US            S  \n",
       "3               CA            M  \n",
       "4               CA            M  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "work_year              int64\n",
       "experience_level      object\n",
       "employment_type       object\n",
       "job_title             object\n",
       "salary                 int64\n",
       "salary_currency       object\n",
       "salary_in_usd          int64\n",
       "employee_residence    object\n",
       "remote_ratio           int64\n",
       "company_location      object\n",
       "company_size          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract categorical variables\n",
    "cat_vars = ['experience_level', 'employment_type', 'job_title', 'employee_residence', 'company_location', 'company_size']\n",
    "\n",
    "# Create LabelEncoder object\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode categorical variables as integers\n",
    "for var in cat_vars:\n",
    "    df[var] = encoder.fit_transform(df[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>80000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>85847</td>\n",
       "      <td>26</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>30000</td>\n",
       "      <td>USD</td>\n",
       "      <td>30000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>25500</td>\n",
       "      <td>USD</td>\n",
       "      <td>25500</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>175000</td>\n",
       "      <td>USD</td>\n",
       "      <td>175000</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>120000</td>\n",
       "      <td>USD</td>\n",
       "      <td>120000</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year  experience_level  employment_type  job_title  salary   \n",
       "0       2023                 3                2         84   80000  \\\n",
       "1       2023                 2                0         66   30000   \n",
       "2       2023                 2                0         66   25500   \n",
       "3       2023                 3                2         47  175000   \n",
       "4       2023                 3                2         47  120000   \n",
       "\n",
       "  salary_currency  salary_in_usd  employee_residence  remote_ratio   \n",
       "0             EUR          85847                  26           100  \\\n",
       "1             USD          30000                  75           100   \n",
       "2             USD          25500                  75           100   \n",
       "3             USD         175000                  11           100   \n",
       "4             USD         120000                  11           100   \n",
       "\n",
       "   company_location  company_size  \n",
       "0                25             0  \n",
       "1                70             2  \n",
       "2                70             2  \n",
       "3                12             1  \n",
       "4                12             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>85847</td>\n",
       "      <td>26</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>30000</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>25500</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>175000</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>120000</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year  experience_level  employment_type  job_title  salary_in_usd   \n",
       "0       2023                 3                2         84          85847  \\\n",
       "1       2023                 2                0         66          30000   \n",
       "2       2023                 2                0         66          25500   \n",
       "3       2023                 3                2         47         175000   \n",
       "4       2023                 3                2         47         120000   \n",
       "\n",
       "   employee_residence  remote_ratio  company_location  company_size  \n",
       "0                  26           100                25             0  \n",
       "1                  75           100                70             2  \n",
       "2                  75           100                70             2  \n",
       "3                  11           100                12             1  \n",
       "4                  11           100                12             1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['salary','salary_currency'] , axis='columns', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression - Salary Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, a regression model is going to be trained and tested to predict the salaries of Data Scientists based on the other featuress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3.755000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.593130e-13</td>\n",
       "      <td>1.967948e-16</td>\n",
       "      <td>4.475189e-16</td>\n",
       "      <td>-5.109096e-17</td>\n",
       "      <td>6.055224e-17</td>\n",
       "      <td>2.119329e-16</td>\n",
       "      <td>1.513806e-17</td>\n",
       "      <td>-9.082837e-17</td>\n",
       "      <td>-6.812127e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000133e+00</td>\n",
       "      <td>1.000133e+00</td>\n",
       "      <td>1.000133e+00</td>\n",
       "      <td>1.000133e+00</td>\n",
       "      <td>1.000133e+00</td>\n",
       "      <td>1.000133e+00</td>\n",
       "      <td>1.000133e+00</td>\n",
       "      <td>1.000133e+00</td>\n",
       "      <td>1.000133e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.433303e+00</td>\n",
       "      <td>-2.725008e+00</td>\n",
       "      <td>-1.495172e+01</td>\n",
       "      <td>-2.139921e+00</td>\n",
       "      <td>-2.100622e+00</td>\n",
       "      <td>-3.439432e+00</td>\n",
       "      <td>-9.524327e-01</td>\n",
       "      <td>-3.550953e+00</td>\n",
       "      <td>-2.343022e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.404380e-01</td>\n",
       "      <td>-5.178456e-01</td>\n",
       "      <td>2.592668e-02</td>\n",
       "      <td>-6.831569e-01</td>\n",
       "      <td>-6.752143e-01</td>\n",
       "      <td>4.601861e-01</td>\n",
       "      <td>-9.524327e-01</td>\n",
       "      <td>4.506246e-01</td>\n",
       "      <td>2.078761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-5.404380e-01</td>\n",
       "      <td>5.857357e-01</td>\n",
       "      <td>2.592668e-02</td>\n",
       "      <td>-3.594315e-01</td>\n",
       "      <td>-4.076928e-02</td>\n",
       "      <td>4.601861e-01</td>\n",
       "      <td>-9.524327e-01</td>\n",
       "      <td>4.506246e-01</td>\n",
       "      <td>2.078761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.059945e-01</td>\n",
       "      <td>5.857357e-01</td>\n",
       "      <td>2.592668e-02</td>\n",
       "      <td>3.959278e-01</td>\n",
       "      <td>5.936757e-01</td>\n",
       "      <td>4.601861e-01</td>\n",
       "      <td>1.105918e+00</td>\n",
       "      <td>4.506246e-01</td>\n",
       "      <td>2.078761e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.059945e-01</td>\n",
       "      <td>5.857357e-01</td>\n",
       "      <td>7.514748e+00</td>\n",
       "      <td>2.823868e+00</td>\n",
       "      <td>4.955485e+00</td>\n",
       "      <td>5.641760e-01</td>\n",
       "      <td>1.105918e+00</td>\n",
       "      <td>5.077900e-01</td>\n",
       "      <td>2.758774e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          work_year  experience_level  employment_type     job_title   \n",
       "count  3.755000e+03      3.755000e+03     3.755000e+03  3.755000e+03  \\\n",
       "mean  -1.593130e-13      1.967948e-16     4.475189e-16 -5.109096e-17   \n",
       "std    1.000133e+00      1.000133e+00     1.000133e+00  1.000133e+00   \n",
       "min   -3.433303e+00     -2.725008e+00    -1.495172e+01 -2.139921e+00   \n",
       "25%   -5.404380e-01     -5.178456e-01     2.592668e-02 -6.831569e-01   \n",
       "50%   -5.404380e-01      5.857357e-01     2.592668e-02 -3.594315e-01   \n",
       "75%    9.059945e-01      5.857357e-01     2.592668e-02  3.959278e-01   \n",
       "max    9.059945e-01      5.857357e-01     7.514748e+00  2.823868e+00   \n",
       "\n",
       "       salary_in_usd  employee_residence  remote_ratio  company_location   \n",
       "count   3.755000e+03        3.755000e+03  3.755000e+03      3.755000e+03  \\\n",
       "mean    6.055224e-17        2.119329e-16  1.513806e-17     -9.082837e-17   \n",
       "std     1.000133e+00        1.000133e+00  1.000133e+00      1.000133e+00   \n",
       "min    -2.100622e+00       -3.439432e+00 -9.524327e-01     -3.550953e+00   \n",
       "25%    -6.752143e-01        4.601861e-01 -9.524327e-01      4.506246e-01   \n",
       "50%    -4.076928e-02        4.601861e-01 -9.524327e-01      4.506246e-01   \n",
       "75%     5.936757e-01        4.601861e-01  1.105918e+00      4.506246e-01   \n",
       "max     4.955485e+00        5.641760e-01  1.105918e+00      5.077900e-01   \n",
       "\n",
       "       company_size  \n",
       "count  3.755000e+03  \n",
       "mean  -6.812127e-17  \n",
       "std    1.000133e+00  \n",
       "min   -2.343022e+00  \n",
       "25%    2.078761e-01  \n",
       "50%    2.078761e-01  \n",
       "75%    2.078761e-01  \n",
       "max    2.758774e+00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_scaled converted to dataframe\n",
    "df_scaled = pd.DataFrame(df_scaled, columns = df.columns)\n",
    "\n",
    "# Describing Data Set\n",
    "df_scaled.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the data is standardly scaled and is ready for regression.\n",
    "\n",
    "In the following cell, data is split into train and test sets using `sklearn.train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#seperating features and target\n",
    "features = df.drop('salary_in_usd', axis=1)\n",
    "target = df['salary_in_usd'].values\n",
    "\n",
    "#split dataset into training and test features and targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the training and test sets in order to start training. The test sets are scaled using the paramaters gained from fitting the scaler to the training sets. This decreases bias in the testing of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#reshaping y_train & y_test to apply the scaling transformation\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, the model is built and tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required library to build a neural network model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3004, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.649351</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2         3     4    5     6    7\n",
       "0  0.0  0.0  0.0  2.649351 -49.0  1.0 -45.0 -1.0\n",
       "1  0.0 -1.0 -2.0  1.714286   0.0  1.0   0.0  1.0\n",
       "2  0.0 -1.0 -2.0  1.714286   0.0  1.0   0.0  1.0\n",
       "3  0.0  0.0  0.0  0.727273 -64.0  1.0 -58.0  0.0\n",
       "4  0.0  0.0  0.0  0.727273 -64.0  1.0 -58.0  0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring X_train\n",
    "print(X_train.shape)\n",
    "df2 = pd.DataFrame(X_train)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.391632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.065272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.541679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.863157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.300251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.391632\n",
       "1 -0.065272\n",
       "2 -0.541679\n",
       "3 -0.863157\n",
       "4 -0.300251"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring y_train\n",
    "df3 = pd.DataFrame(y_test)\n",
    "df3.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Sequential` model is built comprising four `Dense` (fully interconnected) layers. It uses the non-linear `RELU` activation function for the hidden layers, and a `linear` output layer. `L2 kernel regularization` is introduced in order to prevent overfitting and promote good generalization to test scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructing model\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(8,)),\n",
    "    Dense(units = 25, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    Dense(units = 10, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    Dense(units = 5, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    Dense(units = 1, activation = 'linear')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model will use the `Adam`(adaptive moment estimation) optimization algorithm, and the `Mean Squared Error` loss function. It is initialized with a `Learning Rate` of 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 25)                225       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                260       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 546\n",
      "Trainable params: 546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#compiling and summarizing model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MeanSquaredError\n",
    "model.compile(optimizer = Adam(learning_rate = 0.001), loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is ready to be fit to the data. It is run for a 1000 `epochs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "76/76 [==============================] - 1s 4ms/step - loss: 1.4617 - val_loss: 0.5151\n",
      "Epoch 2/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5666 - val_loss: 0.4643\n",
      "Epoch 3/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5513 - val_loss: 0.4633\n",
      "Epoch 4/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5501 - val_loss: 0.4538\n",
      "Epoch 5/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5482 - val_loss: 0.4613\n",
      "Epoch 6/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5371 - val_loss: 0.4594\n",
      "Epoch 7/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5323 - val_loss: 0.4619\n",
      "Epoch 8/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5358 - val_loss: 0.4643\n",
      "Epoch 9/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 0.4598\n",
      "Epoch 10/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5282 - val_loss: 0.4537\n",
      "Epoch 11/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5314 - val_loss: 0.4542\n",
      "Epoch 12/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.4537\n",
      "Epoch 13/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 0.4693\n",
      "Epoch 14/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.4596\n",
      "Epoch 15/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5269 - val_loss: 0.4538\n",
      "Epoch 16/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5222 - val_loss: 0.4463\n",
      "Epoch 17/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 0.4523\n",
      "Epoch 18/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5184 - val_loss: 0.4488\n",
      "Epoch 19/200\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.5172 - val_loss: 0.4561\n",
      "Epoch 20/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5335 - val_loss: 0.4550\n",
      "Epoch 21/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.4560\n",
      "Epoch 22/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.4466\n",
      "Epoch 23/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.4536\n",
      "Epoch 24/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.4450\n",
      "Epoch 25/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5165 - val_loss: 0.4458\n",
      "Epoch 26/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5041 - val_loss: 0.4495\n",
      "Epoch 27/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.4738\n",
      "Epoch 28/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 0.4396\n",
      "Epoch 29/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.4496\n",
      "Epoch 30/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 0.5146\n",
      "Epoch 31/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5096 - val_loss: 0.4435\n",
      "Epoch 32/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 0.5591\n",
      "Epoch 33/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5174 - val_loss: 0.4499\n",
      "Epoch 34/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5029 - val_loss: 0.4438\n",
      "Epoch 35/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5180 - val_loss: 0.4848\n",
      "Epoch 36/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5086 - val_loss: 0.4577\n",
      "Epoch 37/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 0.4455\n",
      "Epoch 38/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.5202\n",
      "Epoch 39/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5638 - val_loss: 0.4408\n",
      "Epoch 40/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 0.4444\n",
      "Epoch 41/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4967 - val_loss: 0.4482\n",
      "Epoch 42/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.4460\n",
      "Epoch 43/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4971 - val_loss: 0.4453\n",
      "Epoch 44/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.4419\n",
      "Epoch 45/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.4437\n",
      "Epoch 46/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4949 - val_loss: 0.4502\n",
      "Epoch 47/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4939 - val_loss: 0.4463\n",
      "Epoch 48/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.4495\n",
      "Epoch 49/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 0.4798\n",
      "Epoch 50/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5129 - val_loss: 0.5828\n",
      "Epoch 51/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4988 - val_loss: 0.4521\n",
      "Epoch 52/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4925 - val_loss: 0.4509\n",
      "Epoch 53/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4989 - val_loss: 0.4442\n",
      "Epoch 54/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.4376\n",
      "Epoch 55/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.4433\n",
      "Epoch 56/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.4572\n",
      "Epoch 57/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4920 - val_loss: 0.4382\n",
      "Epoch 58/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.4375\n",
      "Epoch 59/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4896 - val_loss: 0.4551\n",
      "Epoch 60/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4890 - val_loss: 0.4448\n",
      "Epoch 61/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.5082\n",
      "Epoch 62/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.4349\n",
      "Epoch 63/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4860 - val_loss: 0.4888\n",
      "Epoch 64/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4914 - val_loss: 0.4426\n",
      "Epoch 65/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4941 - val_loss: 0.4360\n",
      "Epoch 66/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 0.4361\n",
      "Epoch 67/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.4669\n",
      "Epoch 68/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4893 - val_loss: 0.4350\n",
      "Epoch 69/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4805 - val_loss: 0.4444\n",
      "Epoch 70/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4822 - val_loss: 0.4359\n",
      "Epoch 71/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4913 - val_loss: 0.4416\n",
      "Epoch 72/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.4479\n",
      "Epoch 73/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4789 - val_loss: 0.4847\n",
      "Epoch 74/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.4365\n",
      "Epoch 75/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.4473\n",
      "Epoch 76/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.4423\n",
      "Epoch 77/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.4659\n",
      "Epoch 78/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.4526\n",
      "Epoch 79/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.4358\n",
      "Epoch 80/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4791 - val_loss: 0.4364\n",
      "Epoch 81/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.4387\n",
      "Epoch 82/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.4451\n",
      "Epoch 83/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.4370\n",
      "Epoch 84/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4702 - val_loss: 0.4557\n",
      "Epoch 85/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.4366\n",
      "Epoch 86/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4717 - val_loss: 0.4335\n",
      "Epoch 87/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.4524\n",
      "Epoch 88/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.4790\n",
      "Epoch 89/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.4408\n",
      "Epoch 90/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.4486\n",
      "Epoch 91/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 0.4431\n",
      "Epoch 92/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.4747\n",
      "Epoch 93/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.4327\n",
      "Epoch 94/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4788 - val_loss: 0.4521\n",
      "Epoch 95/200\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.4700 - val_loss: 0.4732\n",
      "Epoch 96/200\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.4698 - val_loss: 0.4609\n",
      "Epoch 97/200\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.4637 - val_loss: 0.4339\n",
      "Epoch 98/200\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.4635 - val_loss: 0.4409\n",
      "Epoch 99/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.4400\n",
      "Epoch 100/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.4354\n",
      "Epoch 101/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4737 - val_loss: 0.4245\n",
      "Epoch 102/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.4337\n",
      "Epoch 103/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.4314\n",
      "Epoch 104/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.4451\n",
      "Epoch 105/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.4264\n",
      "Epoch 106/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.4369\n",
      "Epoch 107/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.4430\n",
      "Epoch 108/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.4421\n",
      "Epoch 109/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.4607\n",
      "Epoch 110/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.4344\n",
      "Epoch 111/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.4364\n",
      "Epoch 112/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.4487\n",
      "Epoch 113/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.4299\n",
      "Epoch 114/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.4281\n",
      "Epoch 115/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.4409\n",
      "Epoch 116/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.4751\n",
      "Epoch 117/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.4334\n",
      "Epoch 118/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.4291\n",
      "Epoch 119/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4562 - val_loss: 0.4468\n",
      "Epoch 120/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.4583\n",
      "Epoch 121/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.4562\n",
      "Epoch 122/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4569 - val_loss: 0.4453\n",
      "Epoch 123/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.4377\n",
      "Epoch 124/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.4244\n",
      "Epoch 125/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.4339\n",
      "Epoch 126/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4698 - val_loss: 0.4430\n",
      "Epoch 127/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.4291\n",
      "Epoch 128/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.4479\n",
      "Epoch 129/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.4400\n",
      "Epoch 130/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.4424\n",
      "Epoch 131/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.4665\n",
      "Epoch 132/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.4320\n",
      "Epoch 133/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.4458\n",
      "Epoch 134/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.4357\n",
      "Epoch 135/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4533 - val_loss: 0.4511\n",
      "Epoch 136/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.4492\n",
      "Epoch 137/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4581 - val_loss: 0.4523\n",
      "Epoch 138/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.4664\n",
      "Epoch 139/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.4464\n",
      "Epoch 140/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.4346\n",
      "Epoch 141/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.4673\n",
      "Epoch 142/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.4335\n",
      "Epoch 143/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4728 - val_loss: 0.4311\n",
      "Epoch 144/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.4667\n",
      "Epoch 145/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.4478\n",
      "Epoch 146/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.4639\n",
      "Epoch 147/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4606 - val_loss: 0.4409\n",
      "Epoch 148/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.4350\n",
      "Epoch 149/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.4551\n",
      "Epoch 150/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.4681\n",
      "Epoch 151/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.4427\n",
      "Epoch 152/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.4559\n",
      "Epoch 153/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.4395\n",
      "Epoch 154/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.4511\n",
      "Epoch 155/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4524 - val_loss: 0.4534\n",
      "Epoch 156/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.4473\n",
      "Epoch 157/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.4596\n",
      "Epoch 158/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.4723\n",
      "Epoch 159/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.4472\n",
      "Epoch 160/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4537 - val_loss: 0.4479\n",
      "Epoch 161/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.4306\n",
      "Epoch 162/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.4418\n",
      "Epoch 163/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.4358\n",
      "Epoch 164/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.4533\n",
      "Epoch 165/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4579 - val_loss: 0.4460\n",
      "Epoch 166/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.4448\n",
      "Epoch 167/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.4387\n",
      "Epoch 168/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.4450\n",
      "Epoch 169/200\n",
      "76/76 [==============================] - 0s 3ms/step - loss: 0.4543 - val_loss: 0.4358\n",
      "Epoch 170/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4478 - val_loss: 0.4561\n",
      "Epoch 171/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.4559\n",
      "Epoch 172/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.4398\n",
      "Epoch 173/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4552 - val_loss: 0.4397\n",
      "Epoch 174/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4473 - val_loss: 0.4295\n",
      "Epoch 175/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.4491\n",
      "Epoch 176/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4574\n",
      "Epoch 177/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4513 - val_loss: 0.4506\n",
      "Epoch 178/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.4393\n",
      "Epoch 179/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.4451\n",
      "Epoch 180/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.4465\n",
      "Epoch 181/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4486 - val_loss: 0.4316\n",
      "Epoch 182/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.4572\n",
      "Epoch 183/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4573 - val_loss: 0.4768\n",
      "Epoch 184/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4550 - val_loss: 0.4466\n",
      "Epoch 185/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4495 - val_loss: 0.4396\n",
      "Epoch 186/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4503 - val_loss: 0.4359\n",
      "Epoch 187/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.4417\n",
      "Epoch 188/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.4343\n",
      "Epoch 189/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.4353\n",
      "Epoch 190/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4478 - val_loss: 0.4748\n",
      "Epoch 191/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.4386\n",
      "Epoch 192/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.4878\n",
      "Epoch 193/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.4498\n",
      "Epoch 194/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.4371\n",
      "Epoch 195/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4483 - val_loss: 0.4492\n",
      "Epoch 196/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.4391\n",
      "Epoch 197/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4459 - val_loss: 0.4555\n",
      "Epoch 198/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4496 - val_loss: 0.4441\n",
      "Epoch 199/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.4580\n",
      "Epoch 200/200\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.4599\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split= 0.2 ,epochs = 200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training finished with loss of = 0.4468 on the training set. It can be said that the model has `low bias`, i.e. fits the training data well. However, the validation loss suggests little over fittin, for it has a 3% increase over the training loss. The model will be further tested for generalization and overfitting over the test set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward propogation will be used to predict the target for the test set `y_hat`, which will be compared with the true target `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mean_squared_error` function is imported from `sklearn` to be applied between `y_hat` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5347085573696958"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_pred = y_hat, y_true = y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, test error is 0.5347, which compared to the training error of 0.0.4468 is a 19.6% increase in error. The model can be said to have high varianve, thus, further improvement is needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real values of `y_hat` and `y_test` can be compared by applying the inverse transformation to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175743.906250</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175743.906250</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95198.796875</td>\n",
       "      <td>98506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95198.796875</td>\n",
       "      <td>73880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114473.210938</td>\n",
       "      <td>117000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>224238.187500</td>\n",
       "      <td>412000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>126817.992188</td>\n",
       "      <td>151000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>87687.234375</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>125564.500000</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>92405.843750</td>\n",
       "      <td>94665.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         0\n",
       "0    175743.906250  170000.0\n",
       "1    175743.906250  135000.0\n",
       "2     95198.796875   98506.0\n",
       "3     95198.796875   73880.0\n",
       "4    114473.210938  117000.0\n",
       "..             ...       ...\n",
       "746  224238.187500  412000.0\n",
       "747  126817.992188  151000.0\n",
       "748   87687.234375  105000.0\n",
       "749  125564.500000  100000.0\n",
       "750   92405.843750   94665.0\n",
       "\n",
       "[751 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_real = pd.DataFrame(scaler.inverse_transform(y_hat))\n",
    "y_test_real = pd.DataFrame(scaler.inverse_transform(y_test))\n",
    "pd.concat([y_hat_real, y_test_real], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen the model has high error margins. There are few things that can be improved. \n",
    "1. The model architecture can be changed, such as the number of hidden layers and/or neurons.\n",
    "2. The hyperparametres can be adjusted, such the learning rate or regularization parametres.\n",
    "3. More training epochs might be needed.\n",
    "4. Further data collection and preperation might be needed.\n",
    "5. Use a different machine learning algorithm such as XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression using XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, an XGBoost learning model will be built to further improve predictions. The `XGBRegressor` class from `xgboost` is used to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost library and the XGBRegressor class are imported\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`XGBRegressor` is initialized with a squared error loss function for the regression task, and a `random_state` to produce repeatable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, ...)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the XGBoost model\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# train the model using X_train and y_train\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is tested on the test set using `xgb_model.predict`, and evaluated using the `sklearn` function `mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.4719166585793818\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# evaluate the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175743.906250</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175743.906250</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95198.796875</td>\n",
       "      <td>98506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95198.796875</td>\n",
       "      <td>73880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114473.210938</td>\n",
       "      <td>117000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>224238.187500</td>\n",
       "      <td>412000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>126817.992188</td>\n",
       "      <td>151000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>87687.234375</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>125564.500000</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>92405.843750</td>\n",
       "      <td>94665.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         0\n",
       "0    175743.906250  170000.0\n",
       "1    175743.906250  135000.0\n",
       "2     95198.796875   98506.0\n",
       "3     95198.796875   73880.0\n",
       "4    114473.210938  117000.0\n",
       "..             ...       ...\n",
       "746  224238.187500  412000.0\n",
       "747  126817.992188  151000.0\n",
       "748   87687.234375  105000.0\n",
       "749  125564.500000  100000.0\n",
       "750   92405.843750   94665.0\n",
       "\n",
       "[751 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_real = pd.DataFrame(scaler.inverse_transform(y_hat))\n",
    "pd.concat([y_pred_real, y_test_real], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, results are slightly better suggesting better generalization and less variance(overfitting)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
